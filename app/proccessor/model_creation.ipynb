{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = pd.read_csv(\"D:/CARRERA/TESIS/forest_explainer_tesis/datasets/Titanic/DataSet_Titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "for i, f in df.iterrows():\n",
    "    print(f['Clase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = df.drop(columns=\"Sobreviviente\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(data,\n",
    "                                                    df[\"Sobreviviente\"], test_size=0.2,\n",
    "                                                    random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import ClassificationTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest_model: RandomForestClassifier = joblib.load(\n",
    "    \"D:/CARRERA/TESIS/forest_explainer_tesis/datasets/Titanic/titanic.joblib\")\n",
    "\n",
    "q_variables_values_list = [\n",
    "    {\n",
    "        \"column_name\": \"Genero\",\n",
    "        \"variables\": [\n",
    "            {\n",
    "                \"old_value\": 0,\n",
    "                \"new_value\": \"Masculino\"\n",
    "            },\n",
    "            {\n",
    "                \"old_value\": 1,\n",
    "                \"new_value\": \"Femenino\"\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"column_name\": \"Clase\",\n",
    "        \"variables\": [\n",
    "            {\n",
    "                \"old_value\": 1,\n",
    "                \"new_value\": \"Primera Clase\"\n",
    "            },\n",
    "            {\n",
    "                \"old_value\": 2,\n",
    "                \"new_value\": \"Segunda Clase\"\n",
    "            },\n",
    "            {\n",
    "                \"old_value\": 3,\n",
    "                \"new_value\": \"Tercera Clase\"\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "target_description = [\n",
    "    {\n",
    "        \"column_name\": \"Sobreviviente\",\n",
    "        \"variables\": [\n",
    "            {\n",
    "                \"old_value\": 0,\n",
    "                \"new_value\": \"Muere\"\n",
    "            },\n",
    "            {\n",
    "                \"old_value\": 1,\n",
    "                \"new_value\": \"Vive\"\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'column_name': 'Genero', 'variables': [{'old_value': 0, 'new_value': 'Masculino'}, {'old_value': 1, 'new_value': 'Femenino'}]}\n",
      "{'column_name': 'Clase', 'variables': [{'old_value': 1, 'new_value': 'Primera Clase'}, {'old_value': 2, 'new_value': 'Segunda Clase'}, {'old_value': 3, 'new_value': 'Tercera Clase'}]}\n",
      "Creating data_table...\n",
      "Creating importance...\n",
      "Creating permutation_importance...\n",
      "Creating SurrogateTree...\n",
      "Creating SurrogateTree rules...\n",
      "Creating SurrogateTree tree...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CARRERA\\TESIS\\Flask_template_auth_with_Dash\\virtual_env\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to execute 'dot', make sure the Graphviz executables are on your systems' PATH\n",
      "Creating matrix...\n",
      "Creating ROC...\n",
      " ---------CREATED EXPLAINER-----------\n"
     ]
    }
   ],
   "source": [
    "explainer_classifier = ClassificationTrainedModel(\n",
    "    name=\"Titanic\",\n",
    "    df=df,\n",
    "    predictors_description=\"features_description\",\n",
    "    target=\"Sobreviviente\",\n",
    "    test_size=0.2,\n",
    "    random_state=123,\n",
    "    model=random_forest_model,\n",
    "    model_description=\"\",\n",
    "    target_description=target_description[0],\n",
    "    q_variables_values_list=q_variables_values_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IRIS MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = pd.read_csv(\"D:/CARRERA/TESIS/forest_explainer_tesis/datasets/IRIS/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = df.drop(columns=\"species\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(data,\n",
    "                                                    df[\"species\"], test_size=0.1,\n",
    "                                                    random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest_model: RandomForestClassifier = RandomForestClassifier(random_state=123)\n",
    "random_forest_model.fit(X=x_train, y=y_train)\n",
    "joblib.dump(random_forest_model, \"iris.tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest_model: RandomForestClassifier = joblib.load(\n",
    "    \"D:/CARRERA/TESIS/forest_explainer_tesis/datasets/IRIS/iris.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['versicolor', 'virginica', 'virginica', 'versicolor', 'setosa',\n",
       "       'virginica', 'versicolor', 'setosa', 'setosa', 'versicolor',\n",
       "       'virginica', 'setosa', 'versicolor', 'virginica', 'virginica'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_model.predict(X=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = pd.read_excel(\"D:/CARRERA/TESIS/forest_explainer_tesis/datasets/wine/Wine_dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Alcohol  Malic_acid   Ash  Alcalinity_of_ash  Magnesium  \\\n",
       "0        1    14.23        1.71  2.43               15.6        127   \n",
       "1        1    13.20        1.78  2.14               11.2        100   \n",
       "2        1    13.16        2.36  2.67               18.6        101   \n",
       "3        1    14.37        1.95  2.50               16.8        113   \n",
       "4        1    13.24        2.59  2.87               21.0        118   \n",
       "..     ...      ...         ...   ...                ...        ...   \n",
       "173      3    13.71        5.65  2.45               20.5         95   \n",
       "174      3    13.40        3.91  2.48               23.0        102   \n",
       "175      3    13.27        4.28  2.26               20.0        120   \n",
       "176      3    13.17        2.59  2.37               20.0        120   \n",
       "177      3    14.13        4.10  2.74               24.5         96   \n",
       "\n",
       "     Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  \\\n",
       "0             2.80        3.06                  0.28             2.29   \n",
       "1             2.65        2.76                  0.26             1.28   \n",
       "2             2.80        3.24                  0.30             2.81   \n",
       "3             3.85        3.49                  0.24             2.18   \n",
       "4             2.80        2.69                  0.39             1.82   \n",
       "..             ...         ...                   ...              ...   \n",
       "173           1.68        0.61                  0.52             1.06   \n",
       "174           1.80        0.75                  0.43             1.41   \n",
       "175           1.59        0.69                  0.43             1.35   \n",
       "176           1.65        0.68                  0.53             1.46   \n",
       "177           2.05        0.76                  0.56             1.35   \n",
       "\n",
       "     Color_intensity   Hue  OD280/OD315_of_diluted_wines  Proline  \n",
       "0               5.64  1.04                          3.92     1065  \n",
       "1               4.38  1.05                          3.40     1050  \n",
       "2               5.68  1.03                          3.17     1185  \n",
       "3               7.80  0.86                          3.45     1480  \n",
       "4               4.32  1.04                          2.93      735  \n",
       "..               ...   ...                           ...      ...  \n",
       "173             7.70  0.64                          1.74      740  \n",
       "174             7.30  0.70                          1.56      750  \n",
       "175            10.20  0.59                          1.56      835  \n",
       "176             9.30  0.60                          1.62      840  \n",
       "177             9.20  0.61                          1.60      560  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = df.drop(columns=\"Class\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(data,\n",
    "                                                    df[\"Class\"], test_size=0.1,\n",
    "                                                    random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wine.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest_model: RandomForestClassifier = RandomForestClassifier(max_depth=4, random_state=123)\n",
    "random_forest_model.fit(X=x_train, y=y_train)\n",
    "joblib.dump(random_forest_model, \"Wine.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_model.predict(x_test[-1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
